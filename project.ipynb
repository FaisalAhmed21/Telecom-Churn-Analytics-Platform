{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce4a138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9b23099b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (1000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>Male</td>\n",
       "      <td>4</td>\n",
       "      <td>88.35</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>353.40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>36.67</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>63.79</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>127.58</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>8</td>\n",
       "      <td>102.34</td>\n",
       "      <td>One-Year</td>\n",
       "      <td>DSL</td>\n",
       "      <td>818.72</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>69.01</td>\n",
       "      <td>Month-to-Month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2208.32</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Gender  Tenure  MonthlyCharges    ContractType  \\\n",
       "0           1   49    Male       4           88.35  Month-to-Month   \n",
       "1           2   43    Male       0           36.67  Month-to-Month   \n",
       "2           3   51  Female       2           63.79  Month-to-Month   \n",
       "3           4   60  Female       8          102.34        One-Year   \n",
       "4           5   42    Male      32           69.01  Month-to-Month   \n",
       "\n",
       "  InternetService  TotalCharges TechSupport Churn  \n",
       "0     Fiber Optic        353.40         Yes   Yes  \n",
       "1     Fiber Optic          0.00         Yes   Yes  \n",
       "2     Fiber Optic        127.58          No   Yes  \n",
       "3             DSL        818.72         Yes   Yes  \n",
       "4             NaN       2208.32          No   Yes  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Load the original customer churn dataset\n",
    "original_df = pd.read_csv('customer_churn_data.csv')\n",
    "print(f\"Original dataset shape: {original_df.shape}\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "90bc396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset shape: (1766, 10)\n",
      "Churn distribution: Churn\n",
      "No     0.5\n",
      "Yes    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>620</td>\n",
       "      <td>47</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>65.56</td>\n",
       "      <td>Two-Year</td>\n",
       "      <td>DSL</td>\n",
       "      <td>1376.76</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242</td>\n",
       "      <td>43</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>61.98</td>\n",
       "      <td>One-Year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.94</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>289</td>\n",
       "      <td>47</td>\n",
       "      <td>Female</td>\n",
       "      <td>17</td>\n",
       "      <td>66.61</td>\n",
       "      <td>One-Year</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>1132.37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>950</td>\n",
       "      <td>47</td>\n",
       "      <td>Female</td>\n",
       "      <td>3</td>\n",
       "      <td>114.13</td>\n",
       "      <td>One-Year</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>342.39</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>947</td>\n",
       "      <td>29</td>\n",
       "      <td>Female</td>\n",
       "      <td>15</td>\n",
       "      <td>98.06</td>\n",
       "      <td>One-Year</td>\n",
       "      <td>Fiber Optic</td>\n",
       "      <td>1470.90</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Gender  Tenure  MonthlyCharges ContractType  \\\n",
       "0         620   47  Female      21           65.56     Two-Year   \n",
       "1         242   43  Female       3           61.98     One-Year   \n",
       "2         289   47  Female      17           66.61     One-Year   \n",
       "3         950   47  Female       3          114.13     One-Year   \n",
       "4         947   29  Female      15           98.06     One-Year   \n",
       "\n",
       "  InternetService  TotalCharges TechSupport Churn  \n",
       "0             DSL       1376.76         Yes    No  \n",
       "1             NaN        185.94          No   Yes  \n",
       "2     Fiber Optic       1132.37         Yes    No  \n",
       "3     Fiber Optic        342.39         Yes   Yes  \n",
       "4     Fiber Optic       1470.90         Yes    No  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Generate realistic synthetic data to remove churn bias\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Identify minority and majority classes (assumes 'Churn' column is 'Yes'/'No')\n",
    "churn_yes = original_df[original_df['Churn'] == 'Yes']\n",
    "churn_no = original_df[original_df['Churn'] == 'No']\n",
    "\n",
    "if len(churn_yes) == 0 or len(churn_no) == 0:\n",
    "    print(\"Error: One of the classes is missing in the dataset. Cannot balance churn.\")\n",
    "    balanced_df = original_df.copy()\n",
    "else:\n",
    "    # Upsample minority class (No) to match majority class (Yes)\n",
    "    churn_no_upsampled = resample(\n",
    "        churn_no,\n",
    "        replace=True,\n",
    "        n_samples=len(churn_yes),\n",
    "        random_state=42\n",
    "    )\n",
    "    # Combine and shuffle for 50-50 balance\n",
    "    balanced_df = pd.concat([churn_yes, churn_no_upsampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Balanced dataset shape: {balanced_df.shape}\")\n",
    "    print(f\"Churn distribution: {balanced_df['Churn'].value_counts(normalize=True)}\")\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d8e23b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset saved to combined_customer_churn_data_balanced.csv\n"
     ]
    }
   ],
   "source": [
    "# 4. Save the unbiased balanced dataset\n",
    "balanced_df.to_csv('combined_customer_churn_data_balanced.csv', index=False)\n",
    "print(\"Balanced dataset saved to combined_customer_churn_data_balanced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "45f34611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.451385</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.194980</td>\n",
       "      <td>-0.094457</td>\n",
       "      <td>1.292908</td>\n",
       "      <td>-1.220586</td>\n",
       "      <td>-0.171857</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.677266</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.401897</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.351396</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.576626</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-1.126108</td>\n",
       "      <td>1.932704</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.931747</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.566397</td>\n",
       "      <td>-1.515267</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.505356</td>\n",
       "      <td>1.261992</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.102698</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.525479</td>\n",
       "      <td>0.591422</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.557085</td>\n",
       "      <td>1.057481</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.225134</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID       Age    Gender    Tenure  MonthlyCharges  ContractType  \\\n",
       "0    0.451385  0.380753 -0.845056 -0.194980       -0.094457      1.292908   \n",
       "2   -0.677266  0.380753 -0.845056 -0.401897       -0.050633     -0.076437   \n",
       "3    1.576626  0.380753 -0.845056 -1.126108        1.932704     -0.076437   \n",
       "4    1.566397 -1.515267 -0.845056 -0.505356        1.261992     -0.076437   \n",
       "5    1.525479  0.591422 -0.845056 -0.557085        1.057481     -0.076437   \n",
       "\n",
       "   InternetService  TotalCharges  TechSupport  Churn  \n",
       "0        -1.220586     -0.171857     0.393541      0  \n",
       "2         0.819279     -0.351396     0.393541      0  \n",
       "3         0.819279     -0.931747     0.393541      1  \n",
       "4         0.819279     -0.102698     0.393541      0  \n",
       "5         0.819279     -0.225134     0.393541      0  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Preprocess the balanced data\n",
    "# Handle missing values, encode categorical variables, scale features\n",
    "df = balanced_df.dropna()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "feature_cols = [col for col in df.columns if col != 'Churn']\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "\n",
    "print(\"Preprocessing complete.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5dab469a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered dataset shape: (1469, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>CustomerID^2</th>\n",
       "      <th>...</th>\n",
       "      <th>ContractType InternetService</th>\n",
       "      <th>ContractType TotalCharges</th>\n",
       "      <th>ContractType TechSupport</th>\n",
       "      <th>InternetService^2</th>\n",
       "      <th>InternetService TotalCharges</th>\n",
       "      <th>InternetService TechSupport</th>\n",
       "      <th>TotalCharges^2</th>\n",
       "      <th>TotalCharges TechSupport</th>\n",
       "      <th>TechSupport^2</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.451385</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.194980</td>\n",
       "      <td>-0.094457</td>\n",
       "      <td>1.292908</td>\n",
       "      <td>-1.220586</td>\n",
       "      <td>-0.171857</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>0.203748</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.578105</td>\n",
       "      <td>-0.222196</td>\n",
       "      <td>0.508812</td>\n",
       "      <td>1.489831</td>\n",
       "      <td>0.209767</td>\n",
       "      <td>-0.480350</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>-0.067633</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.677266</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.401897</td>\n",
       "      <td>-0.050633</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.351396</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>0.458690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062623</td>\n",
       "      <td>0.026860</td>\n",
       "      <td>-0.030081</td>\n",
       "      <td>0.671217</td>\n",
       "      <td>-0.287891</td>\n",
       "      <td>0.322419</td>\n",
       "      <td>0.123479</td>\n",
       "      <td>-0.138289</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.576626</td>\n",
       "      <td>0.380753</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-1.126108</td>\n",
       "      <td>1.932704</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.931747</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>2.485750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062623</td>\n",
       "      <td>0.071220</td>\n",
       "      <td>-0.030081</td>\n",
       "      <td>0.671217</td>\n",
       "      <td>-0.763360</td>\n",
       "      <td>0.322419</td>\n",
       "      <td>0.868152</td>\n",
       "      <td>-0.366680</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.566397</td>\n",
       "      <td>-1.515267</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.505356</td>\n",
       "      <td>1.261992</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.102698</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>2.453598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062623</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>-0.030081</td>\n",
       "      <td>0.671217</td>\n",
       "      <td>-0.084139</td>\n",
       "      <td>0.322419</td>\n",
       "      <td>0.010547</td>\n",
       "      <td>-0.040416</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.525479</td>\n",
       "      <td>0.591422</td>\n",
       "      <td>-0.845056</td>\n",
       "      <td>-0.557085</td>\n",
       "      <td>1.057481</td>\n",
       "      <td>-0.076437</td>\n",
       "      <td>0.819279</td>\n",
       "      <td>-0.225134</td>\n",
       "      <td>0.393541</td>\n",
       "      <td>2.327085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062623</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>-0.030081</td>\n",
       "      <td>0.671217</td>\n",
       "      <td>-0.184447</td>\n",
       "      <td>0.322419</td>\n",
       "      <td>0.050685</td>\n",
       "      <td>-0.088599</td>\n",
       "      <td>0.154874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID       Age    Gender    Tenure  MonthlyCharges  ContractType  \\\n",
       "0    0.451385  0.380753 -0.845056 -0.194980       -0.094457      1.292908   \n",
       "1   -0.677266  0.380753 -0.845056 -0.401897       -0.050633     -0.076437   \n",
       "2    1.576626  0.380753 -0.845056 -1.126108        1.932704     -0.076437   \n",
       "3    1.566397 -1.515267 -0.845056 -0.505356        1.261992     -0.076437   \n",
       "4    1.525479  0.591422 -0.845056 -0.557085        1.057481     -0.076437   \n",
       "\n",
       "   InternetService  TotalCharges  TechSupport  CustomerID^2  ...  \\\n",
       "0        -1.220586     -0.171857     0.393541      0.203748  ...   \n",
       "1         0.819279     -0.351396     0.393541      0.458690  ...   \n",
       "2         0.819279     -0.931747     0.393541      2.485750  ...   \n",
       "3         0.819279     -0.102698     0.393541      2.453598  ...   \n",
       "4         0.819279     -0.225134     0.393541      2.327085  ...   \n",
       "\n",
       "   ContractType InternetService  ContractType TotalCharges  \\\n",
       "0                     -1.578105                  -0.222196   \n",
       "1                     -0.062623                   0.026860   \n",
       "2                     -0.062623                   0.071220   \n",
       "3                     -0.062623                   0.007850   \n",
       "4                     -0.062623                   0.017209   \n",
       "\n",
       "   ContractType TechSupport  InternetService^2  InternetService TotalCharges  \\\n",
       "0                  0.508812           1.489831                      0.209767   \n",
       "1                 -0.030081           0.671217                     -0.287891   \n",
       "2                 -0.030081           0.671217                     -0.763360   \n",
       "3                 -0.030081           0.671217                     -0.084139   \n",
       "4                 -0.030081           0.671217                     -0.184447   \n",
       "\n",
       "   InternetService TechSupport  TotalCharges^2  TotalCharges TechSupport  \\\n",
       "0                    -0.480350        0.029535                 -0.067633   \n",
       "1                     0.322419        0.123479                 -0.138289   \n",
       "2                     0.322419        0.868152                 -0.366680   \n",
       "3                     0.322419        0.010547                 -0.040416   \n",
       "4                     0.322419        0.050685                 -0.088599   \n",
       "\n",
       "   TechSupport^2  Churn  \n",
       "0       0.154874      0  \n",
       "1       0.154874      0  \n",
       "2       0.154874      1  \n",
       "3       0.154874      0  \n",
       "4       0.154874      0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Feature engineering (polynomial features)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(df[feature_cols])\n",
    "X_poly_df = pd.DataFrame(X_poly, columns=poly.get_feature_names_out(feature_cols))\n",
    "X_poly_df['Churn'] = df['Churn'].values\n",
    "\n",
    "print(f\"Feature engineered dataset shape: {X_poly_df.shape}\")\n",
    "X_poly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7f91b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1175, 54), Test shape: (294, 54)\n"
     ]
    }
   ],
   "source": [
    "# 7. Train/test split\n",
    "X = X_poly_df.drop('Churn', axis=1)\n",
    "y = X_poly_df['Churn']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9286b385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoosting</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTrees</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    accuracy        f1  precision    recall   roc_auc\n",
       "RandomForest        1.000000  1.000000        1.0  1.000000  1.000000\n",
       "GradientBoosting    1.000000  1.000000        1.0  1.000000  1.000000\n",
       "AdaBoost            1.000000  1.000000        1.0  1.000000  1.000000\n",
       "ExtraTrees          1.000000  1.000000        1.0  1.000000  1.000000\n",
       "LogisticRegression  0.993197  0.991379        1.0  0.982906  0.991453"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Train high-level models\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    results[name] = {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'roc_auc': roc_auc\n",
    "    }\n",
    "\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "12a60050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: RandomForest\n",
      "accuracy     1.0\n",
      "f1           1.0\n",
      "precision    1.0\n",
      "recall       1.0\n",
      "roc_auc      1.0\n",
      "Name: RandomForest, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluate and select the best model\n",
    "best_model_name = results_df['roc_auc'].idxmax()\n",
    "best_model = models[best_model_name]\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(results_df.loc[best_model_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "07a2f60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, scaler, and feature names saved for Streamlit app.\n"
     ]
    }
   ],
   "source": [
    "# 10. Save the best model, scaler, and feature names for Streamlit app\n",
    "with open('churn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "with open('feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols, f)\n",
    "model_info = {\n",
    "    'model_name': best_model_name,\n",
    "    'metrics': results_df.loc[best_model_name].to_dict()\n",
    "}\n",
    "with open('model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "print(\"Model, scaler, and feature names saved for Streamlit app.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "becadd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating simple model for Streamlit app...\n",
      "Features shape before scaling: (1760, 9)\n",
      "Target distribution: Churn\n",
      "1    883\n",
      "0    877\n",
      "Name: count, dtype: int64\n",
      "Simple Model Performance:\n",
      "Accuracy: 0.8097\n",
      "Precision: 0.7926\n",
      "Recall: 0.8418\n",
      "F1-Score: 0.8164\n",
      "ROC-AUC: 0.8946\n",
      "‚úÖ Simple model saved successfully for Streamlit app!\n",
      "‚úÖ This model uses basic features without polynomial engineering\n",
      "‚úÖ Model trained on 8 features (excluding CustomerID)\n",
      "‚úÖ Scaler trained on 9 features (including CustomerID for consistency)\n"
     ]
    }
   ],
   "source": [
    "# Save a simpler model for the Streamlit app (using basic features only)\n",
    "print(\"Creating simple model for Streamlit app...\")\n",
    "\n",
    "# Define basic feature names (without polynomial features)\n",
    "basic_features = ['CustomerID', 'Age', 'Gender', 'Tenure', 'MonthlyCharges', 'ContractType', 'InternetService', 'TotalCharges', 'TechSupport']\n",
    "\n",
    "# Use the balanced dataset but without polynomial features\n",
    "X_simple = df_balanced[basic_features].copy()  # Basic features only\n",
    "y_simple = df_balanced['Churn'].copy()\n",
    "\n",
    "# Convert target to numeric (0/1 instead of No/Yes)\n",
    "y_simple = (y_simple == 'Yes').astype(int)\n",
    "\n",
    "# Convert CustomerID to numeric for consistency\n",
    "def convert_customer_id(cid):\n",
    "    if isinstance(cid, str):\n",
    "        if cid.startswith('SYN'):\n",
    "            return int(cid[3:])  # 'SYN1126' ‚Üí 1126\n",
    "        else:\n",
    "            return abs(hash(cid)) % 10000\n",
    "    return int(cid)\n",
    "\n",
    "X_simple['CustomerID'] = X_simple['CustomerID'].apply(convert_customer_id)\n",
    "\n",
    "# Encode categorical variables for simple model\n",
    "le_simple = LabelEncoder()\n",
    "categorical_cols_simple = X_simple.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_cols_simple:\n",
    "    X_simple[col] = le_simple.fit_transform(X_simple[col])\n",
    "\n",
    "print(f\"Features shape before scaling: {X_simple.shape}\")\n",
    "print(f\"Target distribution: {y_simple.value_counts()}\")\n",
    "\n",
    "# Scale features\n",
    "scaler_simple = StandardScaler()\n",
    "X_simple_scaled = scaler_simple.fit_transform(X_simple[basic_features])\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_simple_scaled = pd.DataFrame(X_simple_scaled, columns=basic_features, index=X_simple.index)\n",
    "\n",
    "# Train-test split (exclude CustomerID for training)\n",
    "feature_cols_for_training = [col for col in basic_features if col != 'CustomerID']\n",
    "X_train_simple, X_test_simple, y_train_simple, y_test_simple = train_test_split(\n",
    "    X_simple_scaled[feature_cols_for_training], y_simple, test_size=0.2, random_state=42, stratify=y_simple\n",
    ")\n",
    "\n",
    "# Train a simple logistic regression model\n",
    "lr_simple = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_simple.fit(X_train_simple, y_train_simple)\n",
    "\n",
    "# Evaluate simple model\n",
    "y_pred_simple = lr_simple.predict(X_test_simple)\n",
    "y_pred_proba_simple = lr_simple.predict_proba(X_test_simple)[:, 1]\n",
    "\n",
    "simple_accuracy = accuracy_score(y_test_simple, y_pred_simple)\n",
    "simple_precision = precision_score(y_test_simple, y_pred_simple)\n",
    "simple_recall = recall_score(y_test_simple, y_pred_simple)\n",
    "simple_f1 = f1_score(y_test_simple, y_pred_simple)\n",
    "simple_roc_auc = roc_auc_score(y_test_simple, y_pred_proba_simple)\n",
    "\n",
    "print(f\"Simple Model Performance:\")\n",
    "print(f\"Accuracy: {simple_accuracy:.4f}\")\n",
    "print(f\"Precision: {simple_precision:.4f}\")\n",
    "print(f\"Recall: {simple_recall:.4f}\")\n",
    "print(f\"F1-Score: {simple_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {simple_roc_auc:.4f}\")\n",
    "\n",
    "# Save simple model for Streamlit app\n",
    "with open('churn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(lr_simple, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_simple, f)\n",
    "with open('feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(basic_features, f)\n",
    "\n",
    "# Save simple model info\n",
    "simple_model_info = {\n",
    "    'model_name': 'LogisticRegression (Simple)',\n",
    "    'metrics': {\n",
    "        'accuracy': simple_accuracy,\n",
    "        'precision': simple_precision,\n",
    "        'recall': simple_recall,\n",
    "        'f1': simple_f1,\n",
    "        'roc_auc': simple_roc_auc\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(simple_model_info, f)\n",
    "\n",
    "print(\"‚úÖ Simple model saved successfully for Streamlit app!\")\n",
    "print(\"‚úÖ This model uses basic features without polynomial engineering\")\n",
    "print(f\"‚úÖ Model trained on {len(feature_cols_for_training)} features (excluding CustomerID)\")\n",
    "print(f\"‚úÖ Scaler trained on {len(basic_features)} features (including CustomerID for consistency)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "53117872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training advanced models on balanced dataset...\n",
      "============================================================\n",
      "Checking for NaN values...\n",
      "Total NaN values: 54\n",
      "Filling NaN values...\n",
      "Checking for infinite values...\n",
      "Total infinite values: 0\n",
      "Enhanced features shape: (1760, 14)\n",
      "Final NaN count: 54\n",
      "Scaled data NaN count: 54\n",
      "Scaled data infinite count: 0\n",
      "Training set size: (1408, 13)\n",
      "Test set size: (352, 13)\n",
      "\n",
      "Training RandomForest...\n",
      "  ‚úÖ Accuracy: 0.9062\n",
      "  ‚úÖ Precision: 0.8871\n",
      "  ‚úÖ Recall: 0.9322\n",
      "  ‚úÖ F1-Score: 0.9091\n",
      "  ‚úÖ ROC-AUC: 0.9721\n",
      "\n",
      "Training ExtraTrees...\n",
      "  ‚úÖ Accuracy: 0.8892\n",
      "  ‚úÖ Precision: 0.8632\n",
      "  ‚úÖ Recall: 0.9266\n",
      "  ‚úÖ F1-Score: 0.8937\n",
      "  ‚úÖ ROC-AUC: 0.9719\n",
      "\n",
      "Training AdaBoost...\n",
      "  ‚ùå Error training AdaBoost: Input X contains NaN.\n",
      "AdaBoostClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "Training LogisticRegression_L2...\n",
      "  ‚ùå Error training LogisticRegression_L2: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "Training LogisticRegression_L1...\n",
      "  ‚ùå Error training LogisticRegression_L1: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "Training LogisticRegression_Elastic...\n",
      "  ‚ùå Error training LogisticRegression_Elastic: Input X contains NaN.\n",
      "LogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values\n",
      "\n",
      "============================================================\n",
      "ADVANCED MODELS COMPARISON\n",
      "============================================================\n",
      "          Model  Accuracy  Precision  Recall  F1-Score  ROC-AUC\n",
      "0  RandomForest    0.9062     0.8871  0.9322    0.9091   0.9721\n",
      "1    ExtraTrees    0.8892     0.8632  0.9266    0.8937   0.9719\n",
      "\n",
      "üèÜ BEST MODEL: RandomForest\n",
      "üéØ Best Accuracy: 0.9062 (90.62%)\n",
      "\n",
      "‚úÖ Best model (RandomForest) saved successfully!\n",
      "‚úÖ Enhanced features used: 13\n",
      "‚úÖ Dataset is perfectly balanced: 50% churn / 50% no-churn\n",
      "‚úÖ Model achieves 90.62% accuracy on balanced data!\n"
     ]
    }
   ],
   "source": [
    "# Advanced Model Training on Balanced Dataset\n",
    "print(\"Training advanced models on balanced dataset...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the balanced dataset with proper feature engineering\n",
    "X_balanced_enh = df_balanced[basic_features].copy()  \n",
    "y_balanced_enh = (df_balanced['Churn'] == 'Yes').astype(int)\n",
    "\n",
    "# Convert CustomerID properly\n",
    "X_balanced_enh['CustomerID'] = X_balanced_enh['CustomerID'].apply(convert_customer_id)\n",
    "\n",
    "# Encode categorical variables\n",
    "le_enh = LabelEncoder()\n",
    "categorical_cols_enh = X_balanced_enh.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_cols_enh:\n",
    "    X_balanced_enh[col] = le_enh.fit_transform(X_balanced_enh[col])\n",
    "\n",
    "# Feature Engineering: Add interaction features\n",
    "X_balanced_enh['MonthlyPerYear'] = X_balanced_enh['MonthlyCharges'] * 12\n",
    "X_balanced_enh['ChargesPerTenure'] = X_balanced_enh['TotalCharges'] / (X_balanced_enh['Tenure'] + 1)\n",
    "X_balanced_enh['AgeGroup'] = pd.cut(X_balanced_enh['Age'], bins=[0, 25, 45, 65, 100], labels=[0, 1, 2, 3])\n",
    "X_balanced_enh['TenureGroup'] = pd.cut(X_balanced_enh['Tenure'], bins=[0, 12, 24, 48, 100], labels=[0, 1, 2, 3])\n",
    "X_balanced_enh['ChargeRatio'] = X_balanced_enh['MonthlyCharges'] / (X_balanced_enh['TotalCharges'] + 1)\n",
    "\n",
    "# Handle any NaN or infinite values\n",
    "print(f\"Checking for NaN values...\")\n",
    "nan_count = X_balanced_enh.isnull().sum().sum()\n",
    "print(f\"Total NaN values: {nan_count}\")\n",
    "\n",
    "if nan_count > 0:\n",
    "    print(\"Filling NaN values...\")\n",
    "    # Fill NaN values with median for numerical columns\n",
    "    numerical_cols = X_balanced_enh.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        if X_balanced_enh[col].isnull().sum() > 0:\n",
    "            median_val = X_balanced_enh[col].median()\n",
    "            X_balanced_enh[col].fillna(median_val, inplace=True)\n",
    "            print(f\"  Filled {col} NaN values with median: {median_val}\")\n",
    "\n",
    "# Handle infinite values\n",
    "print(\"Checking for infinite values...\")\n",
    "inf_mask = np.isinf(X_balanced_enh.select_dtypes(include=[np.number]))\n",
    "inf_count = inf_mask.sum().sum()\n",
    "print(f\"Total infinite values: {inf_count}\")\n",
    "\n",
    "if inf_count > 0:\n",
    "    print(\"Replacing infinite values...\")\n",
    "    X_balanced_enh.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    # Fill the new NaNs with median\n",
    "    for col in numerical_cols:\n",
    "        if X_balanced_enh[col].isnull().sum() > 0:\n",
    "            median_val = X_balanced_enh[col].median()\n",
    "            X_balanced_enh[col].fillna(median_val, inplace=True)\n",
    "\n",
    "print(f\"Enhanced features shape: {X_balanced_enh.shape}\")\n",
    "print(f\"Final NaN count: {X_balanced_enh.isnull().sum().sum()}\")\n",
    "\n",
    "# Scale features (excluding CustomerID for training)\n",
    "feature_cols_enh = [col for col in X_balanced_enh.columns if col != 'CustomerID']\n",
    "scaler_enh = StandardScaler()\n",
    "X_balanced_enh_scaled = scaler_enh.fit_transform(X_balanced_enh[feature_cols_enh])\n",
    "X_balanced_enh_scaled = pd.DataFrame(X_balanced_enh_scaled, columns=feature_cols_enh, index=X_balanced_enh.index)\n",
    "\n",
    "# Final check for NaN/infinite in scaled data\n",
    "print(f\"Scaled data NaN count: {X_balanced_enh_scaled.isnull().sum().sum()}\")\n",
    "print(f\"Scaled data infinite count: {np.isinf(X_balanced_enh_scaled.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Train-test split\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_balanced_enh_scaled, y_balanced_enh, test_size=0.2, random_state=42, stratify=y_balanced_enh\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train_enh.shape}\")\n",
    "print(f\"Test set size: {X_test_enh.shape}\")\n",
    "\n",
    "# Define advanced models to test (using ones that can handle various data better)\n",
    "advanced_models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42, n_jobs=-1),\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42, n_jobs=-1),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=1.0, random_state=42),\n",
    "    'LogisticRegression_L2': LogisticRegression(C=1.0, max_iter=1000, random_state=42),\n",
    "    'LogisticRegression_L1': LogisticRegression(C=1.0, penalty='l1', solver='liblinear', max_iter=1000, random_state=42),\n",
    "    'LogisticRegression_Elastic': LogisticRegression(C=1.0, penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate all models\n",
    "advanced_results = {}\n",
    "\n",
    "for model_name, model in advanced_models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model.fit(X_train_enh, y_train_enh)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_enh)\n",
    "        y_pred_proba = model.predict_proba(X_test_enh)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test_enh, y_pred)\n",
    "        precision = precision_score(y_test_enh, y_pred)\n",
    "        recall = recall_score(y_test_enh, y_pred)\n",
    "        f1 = f1_score(y_test_enh, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test_enh, y_pred_proba)\n",
    "        \n",
    "        # Store results\n",
    "        advanced_results[model_name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc\n",
    "        }\n",
    "        \n",
    "        print(f\"  ‚úÖ Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  ‚úÖ Precision: {precision:.4f}\")\n",
    "        print(f\"  ‚úÖ Recall: {recall:.4f}\")\n",
    "        print(f\"  ‚úÖ F1-Score: {f1:.4f}\")\n",
    "        print(f\"  ‚úÖ ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error training {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANCED MODELS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "results_comparison = []\n",
    "for model_name, results in advanced_results.items():\n",
    "    results_comparison.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': results['accuracy'],\n",
    "        'Precision': results['precision'],\n",
    "        'Recall': results['recall'],\n",
    "        'F1-Score': results['f1'],\n",
    "        'ROC-AUC': results['roc_auc']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(results_comparison)\n",
    "comparison_df = comparison_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Find best model\n",
    "best_model_name_overall = comparison_df.iloc[0]['Model']\n",
    "best_accuracy_overall = comparison_df.iloc[0]['Accuracy']\n",
    "best_model = advanced_results[best_model_name_overall]['model']\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name_overall}\")\n",
    "print(f\"üéØ Best Accuracy: {best_accuracy_overall:.4f} ({best_accuracy_overall*100:.2f}%)\")\n",
    "\n",
    "# Save best model for Streamlit app\n",
    "with open('churn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_enh, f)\n",
    "with open('feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols_enh, f)\n",
    "\n",
    "# Save model info\n",
    "model_info_final = {\n",
    "    'model_name': best_model_name_overall,\n",
    "    'metrics': {\n",
    "        'accuracy': advanced_results[best_model_name_overall]['accuracy'],\n",
    "        'precision': advanced_results[best_model_name_overall]['precision'],\n",
    "        'recall': advanced_results[best_model_name_overall]['recall'],\n",
    "        'f1': advanced_results[best_model_name_overall]['f1'],\n",
    "        'roc_auc': advanced_results[best_model_name_overall]['roc_auc']\n",
    "    },\n",
    "    'features': feature_cols_enh,\n",
    "    'feature_count': len(feature_cols_enh)\n",
    "}\n",
    "\n",
    "with open('model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(model_info_final, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Best model ({best_model_name_overall}) saved successfully!\")\n",
    "print(f\"‚úÖ Enhanced features used: {len(feature_cols_enh)}\")\n",
    "print(f\"‚úÖ Dataset is perfectly balanced: 50% churn / 50% no-churn\")\n",
    "print(f\"‚úÖ Model achieves {best_accuracy_overall*100:.2f}% accuracy on balanced data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "59aa21a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FIXING NaN VALUES AND TESTING MORE MODELS\n",
      "============================================================\n",
      "Using SimpleImputer to handle all NaN values...\n",
      "Clean data NaN count: 0\n",
      "Clean data infinite count: 0\n",
      "\n",
      "Training RandomForest on clean data...\n",
      "  ‚úÖ Accuracy: 0.9006 (90.06%)\n",
      "  ‚úÖ Precision: 0.8777\n",
      "  ‚úÖ Recall: 0.9322\n",
      "  ‚úÖ F1-Score: 0.9041\n",
      "  ‚úÖ ROC-AUC: 0.9714\n",
      "\n",
      "Training ExtraTrees on clean data...\n",
      "  ‚úÖ Accuracy: 0.8949 (89.49%)\n",
      "  ‚úÖ Precision: 0.8723\n",
      "  ‚úÖ Recall: 0.9266\n",
      "  ‚úÖ F1-Score: 0.8986\n",
      "  ‚úÖ ROC-AUC: 0.9725\n",
      "\n",
      "Training AdaBoost on clean data...\n",
      "  ‚úÖ Accuracy: 0.8494 (84.94%)\n",
      "  ‚úÖ Precision: 0.8483\n",
      "  ‚úÖ Recall: 0.8531\n",
      "  ‚úÖ F1-Score: 0.8507\n",
      "  ‚úÖ ROC-AUC: 0.9527\n",
      "\n",
      "Training LogisticRegression_L2 on clean data...\n",
      "  ‚úÖ Accuracy: 0.8295 (82.95%)\n",
      "  ‚úÖ Precision: 0.8232\n",
      "  ‚úÖ Recall: 0.8418\n",
      "  ‚úÖ F1-Score: 0.8324\n",
      "  ‚úÖ ROC-AUC: 0.9015\n",
      "\n",
      "Training LogisticRegression_L1 on clean data...\n",
      "  ‚úÖ Accuracy: 0.8295 (82.95%)\n",
      "  ‚úÖ Precision: 0.8232\n",
      "  ‚úÖ Recall: 0.8418\n",
      "  ‚úÖ F1-Score: 0.8324\n",
      "  ‚úÖ ROC-AUC: 0.9015\n",
      "\n",
      "Training LogisticRegression_Elastic on clean data...\n",
      "  ‚úÖ Accuracy: 0.8295 (82.95%)\n",
      "  ‚úÖ Precision: 0.8232\n",
      "  ‚úÖ Recall: 0.8418\n",
      "  ‚úÖ F1-Score: 0.8324\n",
      "  ‚úÖ ROC-AUC: 0.9014\n",
      "\n",
      "Training GradientBoosting on clean data...\n",
      "  ‚úÖ Accuracy: 0.9091 (90.91%)\n",
      "  ‚úÖ Precision: 0.8919\n",
      "  ‚úÖ Recall: 0.9322\n",
      "  ‚úÖ F1-Score: 0.9116\n",
      "  ‚úÖ ROC-AUC: 0.9763\n",
      "\n",
      "Training SVM_RBF on clean data...\n",
      "  ‚úÖ Accuracy: 0.8807 (88.07%)\n",
      "  ‚úÖ Precision: 0.8649\n",
      "  ‚úÖ Recall: 0.9040\n",
      "  ‚úÖ F1-Score: 0.8840\n",
      "  ‚úÖ ROC-AUC: 0.9572\n",
      "\n",
      "============================================================\n",
      "FINAL COMPLETE MODELS COMPARISON\n",
      "============================================================\n",
      "                        Model  Accuracy  Precision  Recall  F1-Score  ROC-AUC\n",
      "0            GradientBoosting    0.9091     0.8919  0.9322    0.9116   0.9763\n",
      "1                RandomForest    0.9006     0.8777  0.9322    0.9041   0.9714\n",
      "2                  ExtraTrees    0.8949     0.8723  0.9266    0.8986   0.9725\n",
      "3                     SVM_RBF    0.8807     0.8649  0.9040    0.8840   0.9572\n",
      "4                    AdaBoost    0.8494     0.8483  0.8531    0.8507   0.9527\n",
      "5       LogisticRegression_L2    0.8295     0.8232  0.8418    0.8324   0.9015\n",
      "6       LogisticRegression_L1    0.8295     0.8232  0.8418    0.8324   0.9015\n",
      "7  LogisticRegression_Elastic    0.8295     0.8232  0.8418    0.8324   0.9014\n",
      "\n",
      "üèÜ FINAL BEST MODEL: GradientBoosting\n",
      "üéØ FINAL Best Accuracy: 0.9091 (90.91%)\n",
      "\n",
      "üìä TOP 3 MODELS:\n",
      "  1. GradientBoosting: 0.9091 (90.91%)\n",
      "  2. RandomForest: 0.9006 (90.06%)\n",
      "  3. ExtraTrees: 0.8949 (89.49%)\n",
      "\n",
      "‚úÖ FINAL best model (GradientBoosting) saved successfully!\n",
      "‚úÖ Model trained on enhanced features: 13\n",
      "‚úÖ Dataset is perfectly balanced: 50% churn / 50% no-churn\n",
      "‚úÖ Model achieves 90.91% accuracy on unbiased data!\n",
      "‚úÖ This is a 12.3% improvement over the simple model!\n"
     ]
    }
   ],
   "source": [
    "# Properly handle NaN values and test additional models\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FIXING NaN VALUES AND TESTING MORE MODELS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a clean copy without NaN values\n",
    "X_clean = X_balanced_enh_scaled.copy()\n",
    "\n",
    "# Use SimpleImputer to properly handle all NaN values\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(\"Using SimpleImputer to handle all NaN values...\")\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_clean_array = imputer.fit_transform(X_clean)\n",
    "X_clean = pd.DataFrame(X_clean_array, columns=feature_cols_enh, index=X_clean.index)\n",
    "\n",
    "print(f\"Clean data NaN count: {X_clean.isnull().sum().sum()}\")\n",
    "print(f\"Clean data infinite count: {np.isinf(X_clean.select_dtypes(include=[np.number])).sum().sum()}\")\n",
    "\n",
    "# Train-test split with clean data\n",
    "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
    "    X_clean, y_balanced_enh, test_size=0.2, random_state=42, stratify=y_balanced_enh\n",
    ")\n",
    "\n",
    "# Test additional models with clean data\n",
    "additional_models = {\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(n_estimators=100, learning_rate=1.0, random_state=42),\n",
    "    'SVM_RBF': SVC(kernel='rbf', C=1.0, probability=True, random_state=42),\n",
    "    'LogisticRegression_L2': LogisticRegression(C=1.0, max_iter=1000, random_state=42),\n",
    "    'LogisticRegression_L1': LogisticRegression(C=1.0, penalty='l1', solver='liblinear', max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Re-train the working models on clean data\n",
    "all_models = {**advanced_models, **additional_models}\n",
    "\n",
    "# Train and evaluate all models on clean data\n",
    "all_results = {}\n",
    "\n",
    "for model_name, model in all_models.items():\n",
    "    print(f\"\\nTraining {model_name} on clean data...\")\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model.fit(X_train_clean, y_train_clean)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_clean)\n",
    "        y_pred_proba = model.predict_proba(X_test_clean)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test_clean, y_pred)\n",
    "        precision = precision_score(y_test_clean, y_pred)\n",
    "        recall = recall_score(y_test_clean, y_pred)\n",
    "        f1 = f1_score(y_test_clean, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test_clean, y_pred_proba)\n",
    "        \n",
    "        # Store results\n",
    "        all_results[model_name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'roc_auc': roc_auc\n",
    "        }\n",
    "        \n",
    "        print(f\"  ‚úÖ Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "        print(f\"  ‚úÖ Precision: {precision:.4f}\")\n",
    "        print(f\"  ‚úÖ Recall: {recall:.4f}\")\n",
    "        print(f\"  ‚úÖ F1-Score: {f1:.4f}\")\n",
    "        print(f\"  ‚úÖ ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Error training {model_name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL COMPLETE MODELS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create final comparison DataFrame\n",
    "all_results_df = []\n",
    "for model_name, results in all_results.items():\n",
    "    all_results_df.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': results['accuracy'],\n",
    "        'Precision': results['precision'],\n",
    "        'Recall': results['recall'],\n",
    "        'F1-Score': results['f1'],\n",
    "        'ROC-AUC': results['roc_auc']\n",
    "    })\n",
    "\n",
    "all_results_df = pd.DataFrame(all_results_df)\n",
    "all_results_df = all_results_df.sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(all_results_df.round(4))\n",
    "\n",
    "# Find best model overall\n",
    "final_best_model_name = all_results_df.iloc[0]['Model']\n",
    "final_best_accuracy = all_results_df.iloc[0]['Accuracy']\n",
    "final_best_model = all_results[final_best_model_name]['model']\n",
    "\n",
    "print(f\"\\nüèÜ FINAL BEST MODEL: {final_best_model_name}\")\n",
    "print(f\"üéØ FINAL Best Accuracy: {final_best_accuracy:.4f} ({final_best_accuracy*100:.2f}%)\")\n",
    "\n",
    "# Show top 3 models\n",
    "print(f\"\\nüìä TOP 3 MODELS:\")\n",
    "for i in range(min(3, len(all_results_df))):\n",
    "    model_info = all_results_df.iloc[i]\n",
    "    print(f\"  {i+1}. {model_info['Model']}: {model_info['Accuracy']:.4f} ({model_info['Accuracy']*100:.2f}%)\")\n",
    "\n",
    "# Save the best model for Streamlit app\n",
    "with open('churn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(final_best_model, f)\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler_enh, f)\n",
    "with open('feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_cols_enh, f)\n",
    "\n",
    "# Save final model info\n",
    "final_model_info = {\n",
    "    'model_name': final_best_model_name,\n",
    "    'metrics': {\n",
    "        'accuracy': all_results[final_best_model_name]['accuracy'],\n",
    "        'precision': all_results[final_best_model_name]['precision'],\n",
    "        'recall': all_results[final_best_model_name]['recall'],\n",
    "        'f1': all_results[final_best_model_name]['f1'],\n",
    "        'roc_auc': all_results[final_best_model_name]['roc_auc']\n",
    "    },\n",
    "    'features': feature_cols_enh,\n",
    "    'feature_count': len(feature_cols_enh),\n",
    "    'training_data_balance': '50% churn / 50% no-churn'\n",
    "}\n",
    "\n",
    "with open('model_info.pkl', 'wb') as f:\n",
    "    pickle.dump(final_model_info, f)\n",
    "\n",
    "print(f\"\\n‚úÖ FINAL best model ({final_best_model_name}) saved successfully!\")\n",
    "print(f\"‚úÖ Model trained on enhanced features: {len(feature_cols_enh)}\")\n",
    "print(f\"‚úÖ Dataset is perfectly balanced: 50% churn / 50% no-churn\")\n",
    "print(f\"‚úÖ Model achieves {final_best_accuracy*100:.2f}% accuracy on unbiased data!\")\n",
    "print(f\"‚úÖ This is a {((final_best_accuracy - 0.8097) / 0.8097) * 100:.1f}% improvement over the simple model!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
